{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d084275e-1542-43e1-bc22-f730bc52e964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72b5da0-d839-442f-a3f3-486513db8007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%Exits amb tots els atributs = 0.7862581244196843\n"
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1.000000, while the model output was 0.000000. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExplainerError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m%Exits amb tots els atributs =\u001b[39m\u001b[33m\"\u001b[39m, Exits)\n\u001b[32m      8\u001b[39m explainer = shap.Explainer(Rf, X_Train)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m shap_values = \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_Test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m shap.plots.beeswarm(shap_values[:,:,\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\shap\\explainers\\_tree.py:380\u001b[39m, in \u001b[36mTreeExplainer.__call__\u001b[39m\u001b[34m(self, X, y, interactions, check_additivity, approximate)\u001b[39m\n\u001b[32m    377\u001b[39m     feature_names = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata_feature_names\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interactions:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_call\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproximate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapproximate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    382\u001b[39m         v = np.stack(v, axis=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# put outputs at the end\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\shap\\explainers\\_tree.py:672\u001b[39m, in \u001b[36mTreeExplainer.shap_values\u001b[39m\u001b[34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[39m\n\u001b[32m    670\u001b[39m out = \u001b[38;5;28mself\u001b[39m._get_shap_output(phi, flat_output)\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model_output == \u001b[33m\"\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# This statements handles the case of multiple outputs\u001b[39;00m\n\u001b[32m    675\u001b[39m \u001b[38;5;66;03m# e.g. a multi-class classification problem, multi-target regression problem\u001b[39;00m\n\u001b[32m    676\u001b[39m \u001b[38;5;66;03m# in this case the output shape corresponds to [num_samples, num_features, num_outputs]\u001b[39;00m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\shap\\explainers\\_tree.py:856\u001b[39m, in \u001b[36mTreeExplainer.assert_additivity\u001b[39m\u001b[34m(self, phi, model_output)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(phi, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    855\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(phi)):\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m         \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpected_value\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    858\u001b[39m     check_sum(\u001b[38;5;28mself\u001b[39m.expected_value + phi.sum(-\u001b[32m1\u001b[39m), model_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mpuig\\Documents\\Uni\\Datathon25\\Datathon-Schneider-Electric\\.pixi\\envs\\default\\Lib\\site-packages\\shap\\explainers\\_tree.py:852\u001b[39m, in \u001b[36mTreeExplainer.assert_additivity.<locals>.check_sum\u001b[39m\u001b[34m(sum_val, model_output)\u001b[39m\n\u001b[32m    846\u001b[39m     err_msg += \u001b[33m\"\u001b[39m\u001b[33m Consider retrying with the feature_perturbation=\u001b[39m\u001b[33m'\u001b[39m\u001b[33minterventional\u001b[39m\u001b[33m'\u001b[39m\u001b[33m option.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    847\u001b[39m err_msg += (\n\u001b[32m    848\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msum_val[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, while the model output was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_output[ind]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. If this\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    850\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m difference is acceptable you can set check_additivity=False to disable this check.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    851\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[31mExplainerError\u001b[39m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1.000000, while the model output was 0.000000. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"dataset.csv\", usecols=range(1,16))\n",
    "y = pd.read_csv(\"dataset.csv\", usecols = [16])\n",
    "X_Train, X_Test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "Rf = RandomForestClassifier(n_estimators=1)\n",
    "Rf.fit(X_Train,y_train)\n",
    "Exits = Rf.score(X_Test,y_test)\n",
    "print(f\"%Exits amb tots els atributs =\", Exits)\n",
    "explainer = shap.Explainer(Rf, X_Train)\n",
    "shap_values = explainer(X_Test)\n",
    "shap.plots.beeswarm(shap_values[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1a51a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10770, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "print(shap_values.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
